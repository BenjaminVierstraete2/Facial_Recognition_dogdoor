{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5928,"status":"ok","timestamp":1674389797145,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"lwtGaWnxXwA_","outputId":"dc21be4d-db77-4249-d925-8be1c0769ac8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 7804059785318963934\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14415560704\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 14357925979793079517\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":1}],"source":["from tensorflow.python.client import device_lib\n","import tensorflow as tf\n","import re\n","\n","\n","physical_devices = tf.config.list_physical_devices('GPU')\n","tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n","device_lib.list_local_devices()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5256,"status":"ok","timestamp":1674389802390,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"Dr0zlW6ZcOCH","outputId":"ec4adcc5-2f22-4eaf-cc66-a249072793e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3657, done.\u001b[K\n","remote: Counting objects: 100% (3657/3657), done.\u001b[K\n","remote: Compressing objects: 100% (3053/3053), done.\u001b[K\n","remote: Total 3657 (delta 968), reused 1510 (delta 552), pack-reused 0\u001b[K\n","Receiving objects: 100% (3657/3657), 47.39 MiB | 18.74 MiB/s, done.\n","Resolving deltas: 100% (968/968), done.\n"]}],"source":["#setup Tensorflow object detection API\n","!git clone --depth 1 https://github.com/tensorflow/models\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LeiWxlRmcRT-","executionInfo":{"status":"ok","timestamp":1674389802390,"user_tz":-60,"elapsed":5,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"}}},"outputs":[],"source":["%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":43242,"status":"ok","timestamp":1674389845628,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"ZwO5JuLCdhs6","outputId":"8c09e0de-fc89-422a-ae10-cbbe62e65dea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.8.0\n","  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (0.2.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (3.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.21.6)\n","Collecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (4.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.51.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.6.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (57.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (3.19.6)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (15.0.6.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.3.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.14.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.12)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (2.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (0.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (0.29.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.38.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.25.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n","Installing collected packages: tf-estimator-nightly, keras, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras","tensorboard","tensorflow"]}}},"metadata":{}}],"source":["with open('/content/models/research/object_detection/packages/tf2/setup.py') as file:\n","    file_content = file.read()\n","\n","# Replace the version number in the file content\n","file_content = re.sub('tf-models-official>=2.5.1', 'tf-models-official==2.8.0', file_content)\n","\n","# Open the destination 'setup.py' file and write the updated content\n","with open('/content/models/research/setup.py', 'w') as file:\n","    file.write(file_content)\n","\n","!pip install tensorflow==2.8.0"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":42695,"status":"ok","timestamp":1674389888309,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"tIFI1nmWdl0D","outputId":"3a22fcee-6c8c-447b-d138-d4b3d421048f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting apache-beam\n","  Downloading apache_beam-2.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official==2.8.0\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu<=2.2.0\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (0.12.0)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (5.4.8)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (4.8.1)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (4.7.0.68)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (2.70.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.8.0->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.3.0)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n","Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.0)\n","Collecting zstandard<1,>=0.18.0\n","  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n","Collecting fasteners<1.0,>=0.3\n","  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n","Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n","Collecting objsize<0.7.0,>=0.6.1\n","  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Collecting tensorflow-io-gcs-filesystem==0.30.0\n","  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (2.11.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (0.1.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (2.16.0)\n","Collecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object-detection==0.1) (7.0.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object-detection==0.1) (2022.12.7)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object-detection==0.1) (4.64.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (2.8.0.dev2021122109)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (15.0.6.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.12)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (2.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.8.0->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official==2.8.0->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official==2.8.0->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official==2.8.0->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official==2.8.0->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official==2.8.0->object-detection==0.1) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official==2.8.0->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (5.10.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (7.1.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (1.12.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (0.38.4)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.8.0->object-detection==0.1) (3.11.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (1.58.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object-detection==0.1) (5.2.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.8.0->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (6.0.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21919977 sha256=c1fa6ae6a976fb8d59a01f2949e79651ec8a00f58620820fcf6a744325f9809f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kotq_ck8/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=46352a32f274c7661435756728b9b5207cd57334a5d3fb3369cb2a11cc05dc3e\n","  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=cad6c5719ea160cb2e5997c07afb2e52615067542246c1a84dbe3619e90c319e\n","  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=cc35a142478ea1ab9d68cca9771719e09ea1d0a547f04402dd62d5275313be5b\n","  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=dacfbf50125a050623743a93ab97b40ed5b28c6a9144b7fcc9d0ae96c103c676\n","  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n","Successfully built object-detection avro-python3 dill seqeval docopt\n","Installing collected packages: sentencepiece, py-cpuinfo, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, fasteners, fastavro, dill, colorama, avro-python3, tensorflow_io, sacrebleu, hdfs, tensorflow-addons, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.29.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.29.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.29.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.3.3\n","    Uninstalling pymongo-4.3.3:\n","      Successfully uninstalled pymongo-4.3.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.6\n","    Uninstalling dill-0.3.6:\n","      Successfully uninstalled dill-0.3.6\n","Successfully installed apache-beam-2.44.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.5 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-io-gcs-filesystem-0.30.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.8.2 tensorflow_io-0.30.0 tf-models-official-2.8.0 tf-slim-1.1.0 zstandard-0.19.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dill","pyparsing"]}}},"metadata":{}}],"source":["!pip install /content/models/research/\n","#tensorflow object detection API"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"1Qm7ktgvfX7G","executionInfo":{"status":"ok","timestamp":1674389888794,"user_tz":-60,"elapsed":500,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"}}},"outputs":[],"source":["!mkdir /content/images\n","!mkdir /content/images/train; mkdir /content/images/validation; mkdir /content/images/test\n","!unzip -q images.zip -d /content/images/all\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1674389889171,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"aBxlWw00w3th","outputId":"70979247-6940-44c8-a3cb-dc853d4e2cb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["532.0 66.0 67.0\n"]}],"source":["image_path = '/content/images/all/images/'\n","train_path = '/content/images/train/'\n","val_path = '/content/images/validation/'\n","test_path = '/content/images/test/'\n","import os\n","\n","numbOfImgs = len(os.listdir(image_path))/2\n","trainCount = (numbOfImgs*0.8)\n","valCount = (numbOfImgs*0.1)-0.5\n","testCount = (numbOfImgs*0.1)+0.5\n","print(trainCount,valCount,testCount)\n","import random\n","\n","for i in range(0, int(trainCount)):\n","    move = random.choice(os.listdir(image_path))\n","    img = move.split('.')[0] + '.jpg'\n","    txtfile = move.split('.')[0] + '.txt'\n","    os.rename(image_path + img, train_path + img)\n","    os.rename(image_path + txtfile, train_path + txtfile)\n","\n","for i in range(0, int(valCount)):\n","    move = random.choice(os.listdir(image_path))\n","    img = move.split('.')[0] + '.jpg'\n","    txtfile = move.split('.')[0] + '.txt'\n","    os.rename(image_path + img, val_path + img)\n","    os.rename(image_path + txtfile, val_path + txtfile)\n","\n","for i in range(0, int(testCount)):\n","    move = random.choice(os.listdir(image_path))\n","    img = move.split('.')[0] + '.jpg'\n","    txtfile = move.split('.')[0] + '.txt'\n","    os.rename(image_path + img, test_path + img)\n","    os.rename(image_path + txtfile, test_path + txtfile)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"peeOyxym2ovp","executionInfo":{"status":"ok","timestamp":1674389889172,"user_tz":-60,"elapsed":3,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"}}},"outputs":[],"source":["%%bash\n","cat <<EOF >> /content/labelmap.txt\n","face\n","EOF"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1311,"status":"ok","timestamp":1674389890481,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"CEYH1iR84XKV"},"outputs":[],"source":["#create tfrecord\n","import tensorflow as tf\n","import os\n","from object_detection.utils import dataset_util\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","\n","\n","def xywh_to_xyxy(box):\n","    x = int(float(box[0]))\n","    y = int(float(box[1]))\n","    w = int(float(box[2]))\n","    h = int(float(box[3]))\n","    xmin = x \n","    ymin = y \n","    xmax = x + w\n","    ymax = y + h\n","    return xmin, ymin, xmax, ymax\n","\n","def write_tfrecord(input,output):\n","# Create a TFRecordWriter\n","    writer = tf.io.TFRecordWriter(output)\n","    # Iterate through all image and text files in the data directory\n","    for file_name in os.listdir(input):\n","        if file_name.endswith('.jpg'):\n","            xmins = []\n","            xmaxs = []\n","            ymins = []\n","            ymaxs = []\n","            classes_text = []\n","            classes = []\n","            # Read the image\n","            image_path = os.path.join(input, file_name)\n","            image_string = open(image_path, 'rb').read()\n","            width, height = Image.open(image_path).size\n","\n","            # Read the corresponding text file\n","            text_file_name = file_name.replace('.jpg', '.txt')\n","            text_file_path = os.path.join(input, text_file_name)\n","            with open(text_file_path, 'r') as f:\n","                lines = f.readlines()\n","                \n","            for line in lines:\n","                # Split the line into parts\n","                parts = line.strip().split(' ')\n","                class_ind = int(parts[0])\n","                class_label = 'face'\n","                box = parts[1:]\n","                box = [int(i) for i in box]\n","                box = xywh_to_xyxy(box)\n","                #normalize images\n","                xmins.append(box[0] / width)\n","                xmaxs.append(box[2] / width)\n","                ymins.append(box[1] / height)\n","                ymaxs.append(box[3] / height)\n","                classes_text.append(class_label.encode('utf8'))\n","                classes.append(class_ind)\n","                \n","                # Create a feature dictionary\n","            feature = {\n","                'image/height': dataset_util.int64_feature(height),\n","                'image/width': dataset_util.int64_feature(width),\n","                'image/filename': dataset_util.bytes_feature(file_name.encode('utf8')),\n","                'image/source_id': dataset_util.bytes_feature(file_name.encode('utf8')),\n","                'image/encoded': dataset_util.bytes_feature(image_string),\n","                'image/format': dataset_util.bytes_feature('jpg'.encode('utf8')),\n","                'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","                'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","                'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","                'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","                'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","                'image/object/class/label': dataset_util.int64_list_feature(classes),\n","            }\n","            # Create a example protocol buffer\n","            example = tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","            # Serialize the example to a string\n","            serialized = example.SerializeToString()\n","\n","            # Write the serialized example to the TFRecord file\n","            writer.write(serialized)\n","\n","    # Close the TFRecordWriter\n","    writer.close()\n","\n","#create records\n","train_path = '/content/images/train/'\n","val_path = '/content/images/validation/'\n","test_path = '/content/images/test/'\n","write_tfrecord(train_path,'/content/train.tfrecord')\n","write_tfrecord(val_path,'/content/val.tfrecord')\n","write_tfrecord(test_path,'/content/test.tfrecord')\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1674389890481,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"NIC3H0_zHgOx","outputId":"d7ec2d71-073d-4d09-ce41-807f8048c0ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["not empty\n","not empty\n"]}],"source":["#check if records are not empty\n","with open('/content/val.tfrecord', 'rb') as f:\n","    byte_content = f.read()\n","    if not byte_content:\n","      print(\"TFRecord is empty\")\n","    else:\n","      print(\"not empty\")\n","\n","with open('/content/train.tfrecord', 'rb') as f:\n","    byte_content = f.read()\n","    if not byte_content:\n","      print(\"TFRecord is empty\")\n","    else:\n","      print(\"not empty\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1674389890845,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"Qb8QrXZT9oLu","outputId":"da35a831-f9ba-4f46-97c6-662c53980e5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/benj\n"]},{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args=['wget', 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'], returncode=0)"]},"metadata":{},"execution_count":11}],"source":["#Get correct model \n","model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n","pretrained_checkpoint = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n","base_pipeline_file = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'\n","\n","#create own folder\n","%mkdir /content/models/benj/\n","%cd /content/models/benj/\n","\n","import subprocess\n","import tarfile\n","\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","subprocess.run([\"wget\", download_tar])\n","\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()\n","\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","subprocess.run([\"wget\", download_config])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1674389890846,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"w6IWS4g3Ay-w"},"outputs":[],"source":["# Create labelmap.pbtxt file\n","path_to_labeltxt = '/content/labelmap.txt'\n","with open(path_to_labeltxt, 'r') as f:\n","    labels = [line.strip() for line in f.readlines()]\n","\n","path_to_labelpbtxt = '/content/labelmap.pbtxt'\n","with open(path_to_labelpbtxt,'w') as f:\n","    for i, label in enumerate(labels):\n","        f.write('item {\\n' +'  id: %d\\n' % (i + 1) + '  name: \\'%s\\'\\n' % label + '}\\n' + '\\n')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1674389890846,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"8dhEikjk_s8c","outputId":"c53faef8-fcce-407d-af19-62801ef9d30b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total classes: 1\n"]}],"source":["batch_size = 16\n","num_steps = 40000\n","\n","pipeline_fname = '/content/models/benj/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/models/benj/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes('/content/labelmap.pbtxt')\n","print('Total classes:', num_classes)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1674389891206,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"0WWruisfB8-_","outputId":"694a3ad2-b514-4268-a9f0-c41f17da99ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/benj\n","writing custom configuration file\n","# SSD with Mobilenet v2 FPN-lite (go/fpn-lite) feature extractor, shared box\n","# predictor and focal loss (a mobile version of Retinanet).\n","# Retinanet: see Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","# Train on TPU-8\n","#\n","# Achieves 22.2 mAP on COCO17 Val\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 1\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 2\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 320\n","        width: 320\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 128\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true,\n","            decay: 0.997,\n","            epsilon: 0.001,\n","          }\n","        }\n","        num_layers_before_predictor: 4\n","        share_prediction_tower: true\n","        use_depthwise: true\n","        kernel_size: 3\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2_fpn_keras'\n","      use_depthwise: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","        additional_layer_depth: 128\n","      }\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          random_normal_initializer {\n","            stddev: 0.01\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.997,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 2.0\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/models/benj/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  num_steps: 5000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_crop_image {\n","      min_object_covered: 0.0\n","      min_aspect_ratio: 0.75\n","      max_aspect_ratio: 3.0\n","      min_area: 0.75\n","      max_area: 1.0\n","      overlap_thresh: 0.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .08\n","          total_steps: 50000\n","          warmup_learning_rate: .026666\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/train.tfrecord\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/val.tfrecord\"\n","  }\n","}\n","\n"]}],"source":["# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n","import re\n","\n","%cd /content/models/benj\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # Set fine_tune_checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"', 'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    # Set tfrecord files for train and test datasets\n","    s = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format('/content/train.tfrecord'), s)\n","    s = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format('/content/val.tfrecord'), s)\n","    # Set label_map_path\n","    s = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format('/content/labelmap.pbtxt'), s)\n","    # Set batch_size\n","    s = re.sub('batch_size: [0-9]+',  'batch_size: {}'.format(batch_size), s)\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+', 'num_steps: {}'.format(num_steps), s)\n","    # Set number of classes num_classes\n","    s = re.sub('num_classes: [0-9]+','num_classes: {}'.format(num_classes), s)\n","    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n","    s = re.sub( 'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","    f.write(s)\n","\n","#show config file\n","!cat /content/models/benj/pipeline_file.config"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1644967,"status":"ok","timestamp":1674391536171,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"bMYxu8lhC9Eg","outputId":"f63c5a63-41e6-4b4e-f579-f895814eab1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  warnings.warn(\n","2023-01-22 12:18:16.104751: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0122 12:18:16.118227 140178033769536 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 5000\n","I0122 12:18:16.123623 140178033769536 config_util.py:552] Maybe overwriting train_steps: 5000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0122 12:18:16.123792 140178033769536 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0122 12:18:16.161813 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/train.tfrecord']\n","I0122 12:18:16.166222 140178033769536 dataset_builder.py:162] Reading unweighted datasets: ['/content/train.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/train.tfrecord']\n","I0122 12:18:16.166472 140178033769536 dataset_builder.py:79] Reading record datasets for input file: ['/content/train.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0122 12:18:16.166586 140178033769536 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0122 12:18:16.166680 140178033769536 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0122 12:18:16.169843 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0122 12:18:16.201108 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0122 12:18:29.440365 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0122 12:18:33.824570 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0122 12:18:35.300468 140178033769536 deprecation.py:337] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.8/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.612015 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.613190 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.615365 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.616303 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.618196 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.618984 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.622229 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.623063 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.625055 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 12:19:08.625937 140178033769536 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0122 12:19:09.162323 140173624928000 deprecation.py:541] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 0.730s\n","I0122 12:20:21.824988 140178033769536 model_lib_v2.py:705] Step 100 per-step time 0.730s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11702039,\n"," 'Loss/localization_loss': 0.12558377,\n"," 'Loss/regularization_loss': 0.15368079,\n"," 'Loss/total_loss': 0.39628494,\n"," 'learning_rate': 0.0319994}\n","I0122 12:20:21.825328 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.11702039,\n"," 'Loss/localization_loss': 0.12558377,\n"," 'Loss/regularization_loss': 0.15368079,\n"," 'Loss/total_loss': 0.39628494,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 0.310s\n","I0122 12:20:52.787175 140178033769536 model_lib_v2.py:705] Step 200 per-step time 0.310s\n","INFO:tensorflow:{'Loss/classification_loss': 0.105502754,\n"," 'Loss/localization_loss': 0.07463582,\n"," 'Loss/regularization_loss': 0.15347876,\n"," 'Loss/total_loss': 0.33361733,\n"," 'learning_rate': 0.0373328}\n","I0122 12:20:52.787463 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.105502754,\n"," 'Loss/localization_loss': 0.07463582,\n"," 'Loss/regularization_loss': 0.15347876,\n"," 'Loss/total_loss': 0.33361733,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 0.304s\n","I0122 12:21:23.182301 140178033769536 model_lib_v2.py:705] Step 300 per-step time 0.304s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09291503,\n"," 'Loss/localization_loss': 0.075907536,\n"," 'Loss/regularization_loss': 0.15320095,\n"," 'Loss/total_loss': 0.3220235,\n"," 'learning_rate': 0.0426662}\n","I0122 12:21:23.182604 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.09291503,\n"," 'Loss/localization_loss': 0.075907536,\n"," 'Loss/regularization_loss': 0.15320095,\n"," 'Loss/total_loss': 0.3220235,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 0.304s\n","I0122 12:21:53.605579 140178033769536 model_lib_v2.py:705] Step 400 per-step time 0.304s\n","INFO:tensorflow:{'Loss/classification_loss': 0.119215064,\n"," 'Loss/localization_loss': 0.09210616,\n"," 'Loss/regularization_loss': 0.15288357,\n"," 'Loss/total_loss': 0.36420482,\n"," 'learning_rate': 0.047999598}\n","I0122 12:21:53.605894 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.119215064,\n"," 'Loss/localization_loss': 0.09210616,\n"," 'Loss/regularization_loss': 0.15288357,\n"," 'Loss/total_loss': 0.36420482,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 0.309s\n","I0122 12:22:24.503167 140178033769536 model_lib_v2.py:705] Step 500 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.08450764,\n"," 'Loss/localization_loss': 0.050951675,\n"," 'Loss/regularization_loss': 0.15252936,\n"," 'Loss/total_loss': 0.28798866,\n"," 'learning_rate': 0.053333}\n","I0122 12:22:24.503445 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.08450764,\n"," 'Loss/localization_loss': 0.050951675,\n"," 'Loss/regularization_loss': 0.15252936,\n"," 'Loss/total_loss': 0.28798866,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 0.307s\n","I0122 12:22:55.212371 140178033769536 model_lib_v2.py:705] Step 600 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.08280405,\n"," 'Loss/localization_loss': 0.038919315,\n"," 'Loss/regularization_loss': 0.15216208,\n"," 'Loss/total_loss': 0.27388543,\n"," 'learning_rate': 0.0586664}\n","I0122 12:22:55.212681 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.08280405,\n"," 'Loss/localization_loss': 0.038919315,\n"," 'Loss/regularization_loss': 0.15216208,\n"," 'Loss/total_loss': 0.27388543,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 0.307s\n","I0122 12:23:25.878249 140178033769536 model_lib_v2.py:705] Step 700 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.071566485,\n"," 'Loss/localization_loss': 0.043709897,\n"," 'Loss/regularization_loss': 0.151761,\n"," 'Loss/total_loss': 0.2670374,\n"," 'learning_rate': 0.0639998}\n","I0122 12:23:25.878578 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.071566485,\n"," 'Loss/localization_loss': 0.043709897,\n"," 'Loss/regularization_loss': 0.151761,\n"," 'Loss/total_loss': 0.2670374,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 0.308s\n","I0122 12:23:56.673118 140178033769536 model_lib_v2.py:705] Step 800 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.07499333,\n"," 'Loss/localization_loss': 0.053976752,\n"," 'Loss/regularization_loss': 0.1513074,\n"," 'Loss/total_loss': 0.2802775,\n"," 'learning_rate': 0.069333196}\n","I0122 12:23:56.673428 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.07499333,\n"," 'Loss/localization_loss': 0.053976752,\n"," 'Loss/regularization_loss': 0.1513074,\n"," 'Loss/total_loss': 0.2802775,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 0.307s\n","I0122 12:24:27.412653 140178033769536 model_lib_v2.py:705] Step 900 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.089145035,\n"," 'Loss/localization_loss': 0.05148032,\n"," 'Loss/regularization_loss': 0.150772,\n"," 'Loss/total_loss': 0.29139736,\n"," 'learning_rate': 0.074666604}\n","I0122 12:24:27.412922 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.089145035,\n"," 'Loss/localization_loss': 0.05148032,\n"," 'Loss/regularization_loss': 0.150772,\n"," 'Loss/total_loss': 0.29139736,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 0.307s\n","I0122 12:24:58.162567 140178033769536 model_lib_v2.py:705] Step 1000 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06604148,\n"," 'Loss/localization_loss': 0.04154934,\n"," 'Loss/regularization_loss': 0.15025534,\n"," 'Loss/total_loss': 0.25784615,\n"," 'learning_rate': 0.08}\n","I0122 12:24:58.162858 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.06604148,\n"," 'Loss/localization_loss': 0.04154934,\n"," 'Loss/regularization_loss': 0.15025534,\n"," 'Loss/total_loss': 0.25784615,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 0.310s\n","I0122 12:25:29.182289 140178033769536 model_lib_v2.py:705] Step 1100 per-step time 0.310s\n","INFO:tensorflow:{'Loss/classification_loss': 0.058036935,\n"," 'Loss/localization_loss': 0.031602457,\n"," 'Loss/regularization_loss': 0.14966232,\n"," 'Loss/total_loss': 0.23930171,\n"," 'learning_rate': 0.07999918}\n","I0122 12:25:29.182609 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.058036935,\n"," 'Loss/localization_loss': 0.031602457,\n"," 'Loss/regularization_loss': 0.14966232,\n"," 'Loss/total_loss': 0.23930171,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 0.309s\n","I0122 12:26:00.073197 140178033769536 model_lib_v2.py:705] Step 1200 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0698271,\n"," 'Loss/localization_loss': 0.046367645,\n"," 'Loss/regularization_loss': 0.14904287,\n"," 'Loss/total_loss': 0.26523763,\n"," 'learning_rate': 0.079996705}\n","I0122 12:26:00.073505 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0698271,\n"," 'Loss/localization_loss': 0.046367645,\n"," 'Loss/regularization_loss': 0.14904287,\n"," 'Loss/total_loss': 0.26523763,\n"," 'learning_rate': 0.079996705}\n","INFO:tensorflow:Step 1300 per-step time 0.309s\n","I0122 12:26:30.925490 140178033769536 model_lib_v2.py:705] Step 1300 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.045804713,\n"," 'Loss/localization_loss': 0.01350863,\n"," 'Loss/regularization_loss': 0.14839616,\n"," 'Loss/total_loss': 0.2077095,\n"," 'learning_rate': 0.0799926}\n","I0122 12:26:30.925799 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.045804713,\n"," 'Loss/localization_loss': 0.01350863,\n"," 'Loss/regularization_loss': 0.14839616,\n"," 'Loss/total_loss': 0.2077095,\n"," 'learning_rate': 0.0799926}\n","INFO:tensorflow:Step 1400 per-step time 0.308s\n","I0122 12:27:01.721621 140178033769536 model_lib_v2.py:705] Step 1400 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.054060537,\n"," 'Loss/localization_loss': 0.028514834,\n"," 'Loss/regularization_loss': 0.14773023,\n"," 'Loss/total_loss': 0.23030561,\n"," 'learning_rate': 0.07998685}\n","I0122 12:27:01.721899 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.054060537,\n"," 'Loss/localization_loss': 0.028514834,\n"," 'Loss/regularization_loss': 0.14773023,\n"," 'Loss/total_loss': 0.23030561,\n"," 'learning_rate': 0.07998685}\n","INFO:tensorflow:Step 1500 per-step time 0.307s\n","I0122 12:27:32.381368 140178033769536 model_lib_v2.py:705] Step 1500 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0596097,\n"," 'Loss/localization_loss': 0.023739541,\n"," 'Loss/regularization_loss': 0.14706984,\n"," 'Loss/total_loss': 0.23041908,\n"," 'learning_rate': 0.07997945}\n","I0122 12:27:32.381675 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0596097,\n"," 'Loss/localization_loss': 0.023739541,\n"," 'Loss/regularization_loss': 0.14706984,\n"," 'Loss/total_loss': 0.23041908,\n"," 'learning_rate': 0.07997945}\n","INFO:tensorflow:Step 1600 per-step time 0.307s\n","I0122 12:28:03.045501 140178033769536 model_lib_v2.py:705] Step 1600 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06547338,\n"," 'Loss/localization_loss': 0.022953602,\n"," 'Loss/regularization_loss': 0.14638188,\n"," 'Loss/total_loss': 0.23480886,\n"," 'learning_rate': 0.079970405}\n","I0122 12:28:03.045834 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.06547338,\n"," 'Loss/localization_loss': 0.022953602,\n"," 'Loss/regularization_loss': 0.14638188,\n"," 'Loss/total_loss': 0.23480886,\n"," 'learning_rate': 0.079970405}\n","INFO:tensorflow:Step 1700 per-step time 0.311s\n","I0122 12:28:34.096706 140178033769536 model_lib_v2.py:705] Step 1700 per-step time 0.311s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05983751,\n"," 'Loss/localization_loss': 0.028425138,\n"," 'Loss/regularization_loss': 0.14569408,\n"," 'Loss/total_loss': 0.23395672,\n"," 'learning_rate': 0.07995972}\n","I0122 12:28:34.096992 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.05983751,\n"," 'Loss/localization_loss': 0.028425138,\n"," 'Loss/regularization_loss': 0.14569408,\n"," 'Loss/total_loss': 0.23395672,\n"," 'learning_rate': 0.07995972}\n","INFO:tensorflow:Step 1800 per-step time 0.308s\n","I0122 12:29:04.871686 140178033769536 model_lib_v2.py:705] Step 1800 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04429319,\n"," 'Loss/localization_loss': 0.021826673,\n"," 'Loss/regularization_loss': 0.14499936,\n"," 'Loss/total_loss': 0.21111922,\n"," 'learning_rate': 0.0799474}\n","I0122 12:29:04.871986 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.04429319,\n"," 'Loss/localization_loss': 0.021826673,\n"," 'Loss/regularization_loss': 0.14499936,\n"," 'Loss/total_loss': 0.21111922,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 0.307s\n","I0122 12:29:35.522862 140178033769536 model_lib_v2.py:705] Step 1900 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.041025814,\n"," 'Loss/localization_loss': 0.012458639,\n"," 'Loss/regularization_loss': 0.14430273,\n"," 'Loss/total_loss': 0.19778718,\n"," 'learning_rate': 0.07993342}\n","I0122 12:29:35.523164 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.041025814,\n"," 'Loss/localization_loss': 0.012458639,\n"," 'Loss/regularization_loss': 0.14430273,\n"," 'Loss/total_loss': 0.19778718,\n"," 'learning_rate': 0.07993342}\n","INFO:tensorflow:Step 2000 per-step time 0.309s\n","I0122 12:30:06.463144 140178033769536 model_lib_v2.py:705] Step 2000 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.042443294,\n"," 'Loss/localization_loss': 0.023487829,\n"," 'Loss/regularization_loss': 0.14358218,\n"," 'Loss/total_loss': 0.2095133,\n"," 'learning_rate': 0.07991781}\n","I0122 12:30:06.463466 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.042443294,\n"," 'Loss/localization_loss': 0.023487829,\n"," 'Loss/regularization_loss': 0.14358218,\n"," 'Loss/total_loss': 0.2095133,\n"," 'learning_rate': 0.07991781}\n","INFO:tensorflow:Step 2100 per-step time 0.312s\n","I0122 12:30:37.617596 140178033769536 model_lib_v2.py:705] Step 2100 per-step time 0.312s\n","INFO:tensorflow:{'Loss/classification_loss': 0.044454407,\n"," 'Loss/localization_loss': 0.017973166,\n"," 'Loss/regularization_loss': 0.14285988,\n"," 'Loss/total_loss': 0.20528746,\n"," 'learning_rate': 0.07990056}\n","I0122 12:30:37.617915 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.044454407,\n"," 'Loss/localization_loss': 0.017973166,\n"," 'Loss/regularization_loss': 0.14285988,\n"," 'Loss/total_loss': 0.20528746,\n"," 'learning_rate': 0.07990056}\n","INFO:tensorflow:Step 2200 per-step time 0.308s\n","I0122 12:31:08.457791 140178033769536 model_lib_v2.py:705] Step 2200 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04060932,\n"," 'Loss/localization_loss': 0.014718237,\n"," 'Loss/regularization_loss': 0.14215313,\n"," 'Loss/total_loss': 0.19748068,\n"," 'learning_rate': 0.07988167}\n","I0122 12:31:08.458084 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.04060932,\n"," 'Loss/localization_loss': 0.014718237,\n"," 'Loss/regularization_loss': 0.14215313,\n"," 'Loss/total_loss': 0.19748068,\n"," 'learning_rate': 0.07988167}\n","INFO:tensorflow:Step 2300 per-step time 0.308s\n","I0122 12:31:39.292560 140178033769536 model_lib_v2.py:705] Step 2300 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04985513,\n"," 'Loss/localization_loss': 0.016232103,\n"," 'Loss/regularization_loss': 0.14151292,\n"," 'Loss/total_loss': 0.20760015,\n"," 'learning_rate': 0.07986114}\n","I0122 12:31:39.292890 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.04985513,\n"," 'Loss/localization_loss': 0.016232103,\n"," 'Loss/regularization_loss': 0.14151292,\n"," 'Loss/total_loss': 0.20760015,\n"," 'learning_rate': 0.07986114}\n","INFO:tensorflow:Step 2400 per-step time 0.307s\n","I0122 12:32:10.043133 140178033769536 model_lib_v2.py:705] Step 2400 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.048461534,\n"," 'Loss/localization_loss': 0.020749217,\n"," 'Loss/regularization_loss': 0.14079393,\n"," 'Loss/total_loss': 0.21000469,\n"," 'learning_rate': 0.07983897}\n","I0122 12:32:10.043451 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.048461534,\n"," 'Loss/localization_loss': 0.020749217,\n"," 'Loss/regularization_loss': 0.14079393,\n"," 'Loss/total_loss': 0.21000469,\n"," 'learning_rate': 0.07983897}\n","INFO:tensorflow:Step 2500 per-step time 0.309s\n","I0122 12:32:40.943321 140178033769536 model_lib_v2.py:705] Step 2500 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.035968326,\n"," 'Loss/localization_loss': 0.0150319375,\n"," 'Loss/regularization_loss': 0.14006701,\n"," 'Loss/total_loss': 0.19106728,\n"," 'learning_rate': 0.079815164}\n","I0122 12:32:40.943621 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.035968326,\n"," 'Loss/localization_loss': 0.0150319375,\n"," 'Loss/regularization_loss': 0.14006701,\n"," 'Loss/total_loss': 0.19106728,\n"," 'learning_rate': 0.079815164}\n","INFO:tensorflow:Step 2600 per-step time 0.306s\n","I0122 12:33:11.570863 140178033769536 model_lib_v2.py:705] Step 2600 per-step time 0.306s\n","INFO:tensorflow:{'Loss/classification_loss': 0.048444632,\n"," 'Loss/localization_loss': 0.016827345,\n"," 'Loss/regularization_loss': 0.13937369,\n"," 'Loss/total_loss': 0.20464566,\n"," 'learning_rate': 0.07978972}\n","I0122 12:33:11.571158 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.048444632,\n"," 'Loss/localization_loss': 0.016827345,\n"," 'Loss/regularization_loss': 0.13937369,\n"," 'Loss/total_loss': 0.20464566,\n"," 'learning_rate': 0.07978972}\n","INFO:tensorflow:Step 2700 per-step time 0.308s\n","I0122 12:33:42.337975 140178033769536 model_lib_v2.py:705] Step 2700 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04562576,\n"," 'Loss/localization_loss': 0.027825138,\n"," 'Loss/regularization_loss': 0.13865237,\n"," 'Loss/total_loss': 0.21210328,\n"," 'learning_rate': 0.07976264}\n","I0122 12:33:42.338271 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.04562576,\n"," 'Loss/localization_loss': 0.027825138,\n"," 'Loss/regularization_loss': 0.13865237,\n"," 'Loss/total_loss': 0.21210328,\n"," 'learning_rate': 0.07976264}\n","INFO:tensorflow:Step 2800 per-step time 0.307s\n","I0122 12:34:13.040925 140178033769536 model_lib_v2.py:705] Step 2800 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0474448,\n"," 'Loss/localization_loss': 0.018319998,\n"," 'Loss/regularization_loss': 0.13796347,\n"," 'Loss/total_loss': 0.20372827,\n"," 'learning_rate': 0.07973392}\n","I0122 12:34:13.041209 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0474448,\n"," 'Loss/localization_loss': 0.018319998,\n"," 'Loss/regularization_loss': 0.13796347,\n"," 'Loss/total_loss': 0.20372827,\n"," 'learning_rate': 0.07973392}\n","INFO:tensorflow:Step 2900 per-step time 0.309s\n","I0122 12:34:43.925150 140178033769536 model_lib_v2.py:705] Step 2900 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.041229013,\n"," 'Loss/localization_loss': 0.010458598,\n"," 'Loss/regularization_loss': 0.13726231,\n"," 'Loss/total_loss': 0.18894993,\n"," 'learning_rate': 0.07970358}\n","I0122 12:34:43.925434 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.041229013,\n"," 'Loss/localization_loss': 0.010458598,\n"," 'Loss/regularization_loss': 0.13726231,\n"," 'Loss/total_loss': 0.18894993,\n"," 'learning_rate': 0.07970358}\n","INFO:tensorflow:Step 3000 per-step time 0.308s\n","I0122 12:35:14.751095 140178033769536 model_lib_v2.py:705] Step 3000 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.046143103,\n"," 'Loss/localization_loss': 0.016903821,\n"," 'Loss/regularization_loss': 0.13659401,\n"," 'Loss/total_loss': 0.19964093,\n"," 'learning_rate': 0.0796716}\n","I0122 12:35:14.751389 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.046143103,\n"," 'Loss/localization_loss': 0.016903821,\n"," 'Loss/regularization_loss': 0.13659401,\n"," 'Loss/total_loss': 0.19964093,\n"," 'learning_rate': 0.0796716}\n","INFO:tensorflow:Step 3100 per-step time 0.314s\n","I0122 12:35:46.168967 140178033769536 model_lib_v2.py:705] Step 3100 per-step time 0.314s\n","INFO:tensorflow:{'Loss/classification_loss': 0.038764495,\n"," 'Loss/localization_loss': 0.016435588,\n"," 'Loss/regularization_loss': 0.13591975,\n"," 'Loss/total_loss': 0.19111983,\n"," 'learning_rate': 0.07963799}\n","I0122 12:35:46.169316 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.038764495,\n"," 'Loss/localization_loss': 0.016435588,\n"," 'Loss/regularization_loss': 0.13591975,\n"," 'Loss/total_loss': 0.19111983,\n"," 'learning_rate': 0.07963799}\n","INFO:tensorflow:Step 3200 per-step time 0.310s\n","I0122 12:36:17.118908 140178033769536 model_lib_v2.py:705] Step 3200 per-step time 0.310s\n","INFO:tensorflow:{'Loss/classification_loss': 0.031669367,\n"," 'Loss/localization_loss': 0.010405565,\n"," 'Loss/regularization_loss': 0.13523386,\n"," 'Loss/total_loss': 0.1773088,\n"," 'learning_rate': 0.07960275}\n","I0122 12:36:17.119205 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.031669367,\n"," 'Loss/localization_loss': 0.010405565,\n"," 'Loss/regularization_loss': 0.13523386,\n"," 'Loss/total_loss': 0.1773088,\n"," 'learning_rate': 0.07960275}\n","INFO:tensorflow:Step 3300 per-step time 0.309s\n","I0122 12:36:48.047190 140178033769536 model_lib_v2.py:705] Step 3300 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0425039,\n"," 'Loss/localization_loss': 0.011019822,\n"," 'Loss/regularization_loss': 0.13453196,\n"," 'Loss/total_loss': 0.18805568,\n"," 'learning_rate': 0.07956588}\n","I0122 12:36:48.047485 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0425039,\n"," 'Loss/localization_loss': 0.011019822,\n"," 'Loss/regularization_loss': 0.13453196,\n"," 'Loss/total_loss': 0.18805568,\n"," 'learning_rate': 0.07956588}\n","INFO:tensorflow:Step 3400 per-step time 0.309s\n","I0122 12:37:18.974144 140178033769536 model_lib_v2.py:705] Step 3400 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03294811,\n"," 'Loss/localization_loss': 0.010611806,\n"," 'Loss/regularization_loss': 0.13383164,\n"," 'Loss/total_loss': 0.17739156,\n"," 'learning_rate': 0.079527386}\n","I0122 12:37:18.974425 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.03294811,\n"," 'Loss/localization_loss': 0.010611806,\n"," 'Loss/regularization_loss': 0.13383164,\n"," 'Loss/total_loss': 0.17739156,\n"," 'learning_rate': 0.079527386}\n","INFO:tensorflow:Step 3500 per-step time 0.308s\n","I0122 12:37:49.790081 140178033769536 model_lib_v2.py:705] Step 3500 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03559368,\n"," 'Loss/localization_loss': 0.013403698,\n"," 'Loss/regularization_loss': 0.13313335,\n"," 'Loss/total_loss': 0.18213072,\n"," 'learning_rate': 0.07948727}\n","I0122 12:37:49.790439 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.03559368,\n"," 'Loss/localization_loss': 0.013403698,\n"," 'Loss/regularization_loss': 0.13313335,\n"," 'Loss/total_loss': 0.18213072,\n"," 'learning_rate': 0.07948727}\n","INFO:tensorflow:Step 3600 per-step time 0.308s\n","I0122 12:38:20.603159 140178033769536 model_lib_v2.py:705] Step 3600 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.043153536,\n"," 'Loss/localization_loss': 0.01577126,\n"," 'Loss/regularization_loss': 0.13244413,\n"," 'Loss/total_loss': 0.19136892,\n"," 'learning_rate': 0.079445526}\n","I0122 12:38:20.603489 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.043153536,\n"," 'Loss/localization_loss': 0.01577126,\n"," 'Loss/regularization_loss': 0.13244413,\n"," 'Loss/total_loss': 0.19136892,\n"," 'learning_rate': 0.079445526}\n","INFO:tensorflow:Step 3700 per-step time 0.309s\n","I0122 12:38:51.488348 140178033769536 model_lib_v2.py:705] Step 3700 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03731485,\n"," 'Loss/localization_loss': 0.010137179,\n"," 'Loss/regularization_loss': 0.13175048,\n"," 'Loss/total_loss': 0.17920251,\n"," 'learning_rate': 0.07940216}\n","I0122 12:38:51.488669 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.03731485,\n"," 'Loss/localization_loss': 0.010137179,\n"," 'Loss/regularization_loss': 0.13175048,\n"," 'Loss/total_loss': 0.17920251,\n"," 'learning_rate': 0.07940216}\n","INFO:tensorflow:Step 3800 per-step time 0.308s\n","I0122 12:39:22.291371 140178033769536 model_lib_v2.py:705] Step 3800 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.029489234,\n"," 'Loss/localization_loss': 0.010870638,\n"," 'Loss/regularization_loss': 0.1310794,\n"," 'Loss/total_loss': 0.17143928,\n"," 'learning_rate': 0.079357184}\n","I0122 12:39:22.291679 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.029489234,\n"," 'Loss/localization_loss': 0.010870638,\n"," 'Loss/regularization_loss': 0.1310794,\n"," 'Loss/total_loss': 0.17143928,\n"," 'learning_rate': 0.079357184}\n","INFO:tensorflow:Step 3900 per-step time 0.308s\n","I0122 12:39:53.100101 140178033769536 model_lib_v2.py:705] Step 3900 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.033692922,\n"," 'Loss/localization_loss': 0.0076670796,\n"," 'Loss/regularization_loss': 0.13040793,\n"," 'Loss/total_loss': 0.17176794,\n"," 'learning_rate': 0.07931058}\n","I0122 12:39:53.100555 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.033692922,\n"," 'Loss/localization_loss': 0.0076670796,\n"," 'Loss/regularization_loss': 0.13040793,\n"," 'Loss/total_loss': 0.17176794,\n"," 'learning_rate': 0.07931058}\n","INFO:tensorflow:Step 4000 per-step time 0.308s\n","I0122 12:40:23.860362 140178033769536 model_lib_v2.py:705] Step 4000 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.029156951,\n"," 'Loss/localization_loss': 0.009683205,\n"," 'Loss/regularization_loss': 0.12972833,\n"," 'Loss/total_loss': 0.16856849,\n"," 'learning_rate': 0.07926236}\n","I0122 12:40:23.860738 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.029156951,\n"," 'Loss/localization_loss': 0.009683205,\n"," 'Loss/regularization_loss': 0.12972833,\n"," 'Loss/total_loss': 0.16856849,\n"," 'learning_rate': 0.07926236}\n","INFO:tensorflow:Step 4100 per-step time 0.312s\n","I0122 12:40:55.048748 140178033769536 model_lib_v2.py:705] Step 4100 per-step time 0.312s\n","INFO:tensorflow:{'Loss/classification_loss': 0.027321562,\n"," 'Loss/localization_loss': 0.0090634115,\n"," 'Loss/regularization_loss': 0.12905644,\n"," 'Loss/total_loss': 0.16544141,\n"," 'learning_rate': 0.07921253}\n","I0122 12:40:55.049043 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.027321562,\n"," 'Loss/localization_loss': 0.0090634115,\n"," 'Loss/regularization_loss': 0.12905644,\n"," 'Loss/total_loss': 0.16544141,\n"," 'learning_rate': 0.07921253}\n","INFO:tensorflow:Step 4200 per-step time 0.310s\n","I0122 12:41:26.003583 140178033769536 model_lib_v2.py:705] Step 4200 per-step time 0.310s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03488064,\n"," 'Loss/localization_loss': 0.01264544,\n"," 'Loss/regularization_loss': 0.12838966,\n"," 'Loss/total_loss': 0.17591575,\n"," 'learning_rate': 0.07916109}\n","I0122 12:41:26.003860 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.03488064,\n"," 'Loss/localization_loss': 0.01264544,\n"," 'Loss/regularization_loss': 0.12838966,\n"," 'Loss/total_loss': 0.17591575,\n"," 'learning_rate': 0.07916109}\n","INFO:tensorflow:Step 4300 per-step time 0.308s\n","I0122 12:41:56.801767 140178033769536 model_lib_v2.py:705] Step 4300 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.035909273,\n"," 'Loss/localization_loss': 0.0132146105,\n"," 'Loss/regularization_loss': 0.12772982,\n"," 'Loss/total_loss': 0.1768537,\n"," 'learning_rate': 0.07910804}\n","I0122 12:41:56.802112 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.035909273,\n"," 'Loss/localization_loss': 0.0132146105,\n"," 'Loss/regularization_loss': 0.12772982,\n"," 'Loss/total_loss': 0.1768537,\n"," 'learning_rate': 0.07910804}\n","INFO:tensorflow:Step 4400 per-step time 0.307s\n","I0122 12:42:27.549782 140178033769536 model_lib_v2.py:705] Step 4400 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03668481,\n"," 'Loss/localization_loss': 0.010337944,\n"," 'Loss/regularization_loss': 0.1271032,\n"," 'Loss/total_loss': 0.17412595,\n"," 'learning_rate': 0.07905338}\n","I0122 12:42:27.550079 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.03668481,\n"," 'Loss/localization_loss': 0.010337944,\n"," 'Loss/regularization_loss': 0.1271032,\n"," 'Loss/total_loss': 0.17412595,\n"," 'learning_rate': 0.07905338}\n","INFO:tensorflow:Step 4500 per-step time 0.306s\n","I0122 12:42:58.169849 140178033769536 model_lib_v2.py:705] Step 4500 per-step time 0.306s\n","INFO:tensorflow:{'Loss/classification_loss': 0.037573364,\n"," 'Loss/localization_loss': 0.01653074,\n"," 'Loss/regularization_loss': 0.12646057,\n"," 'Loss/total_loss': 0.18056467,\n"," 'learning_rate': 0.07899711}\n","I0122 12:42:58.170151 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.037573364,\n"," 'Loss/localization_loss': 0.01653074,\n"," 'Loss/regularization_loss': 0.12646057,\n"," 'Loss/total_loss': 0.18056467,\n"," 'learning_rate': 0.07899711}\n","INFO:tensorflow:Step 4600 per-step time 0.307s\n","I0122 12:43:28.880296 140178033769536 model_lib_v2.py:705] Step 4600 per-step time 0.307s\n","INFO:tensorflow:{'Loss/classification_loss': 0.045254946,\n"," 'Loss/localization_loss': 0.015043274,\n"," 'Loss/regularization_loss': 0.12580585,\n"," 'Loss/total_loss': 0.18610407,\n"," 'learning_rate': 0.078939244}\n","I0122 12:43:28.880637 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.045254946,\n"," 'Loss/localization_loss': 0.015043274,\n"," 'Loss/regularization_loss': 0.12580585,\n"," 'Loss/total_loss': 0.18610407,\n"," 'learning_rate': 0.078939244}\n","INFO:tensorflow:Step 4700 per-step time 0.308s\n","I0122 12:43:59.677819 140178033769536 model_lib_v2.py:705] Step 4700 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.037514012,\n"," 'Loss/localization_loss': 0.011956224,\n"," 'Loss/regularization_loss': 0.12517536,\n"," 'Loss/total_loss': 0.1746456,\n"," 'learning_rate': 0.07887978}\n","I0122 12:43:59.678127 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.037514012,\n"," 'Loss/localization_loss': 0.011956224,\n"," 'Loss/regularization_loss': 0.12517536,\n"," 'Loss/total_loss': 0.1746456,\n"," 'learning_rate': 0.07887978}\n","INFO:tensorflow:Step 4800 per-step time 0.309s\n","I0122 12:44:30.584847 140178033769536 model_lib_v2.py:705] Step 4800 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.040110186,\n"," 'Loss/localization_loss': 0.011752164,\n"," 'Loss/regularization_loss': 0.12453671,\n"," 'Loss/total_loss': 0.17639905,\n"," 'learning_rate': 0.07881871}\n","I0122 12:44:30.585128 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.040110186,\n"," 'Loss/localization_loss': 0.011752164,\n"," 'Loss/regularization_loss': 0.12453671,\n"," 'Loss/total_loss': 0.17639905,\n"," 'learning_rate': 0.07881871}\n","INFO:tensorflow:Step 4900 per-step time 0.309s\n","I0122 12:45:01.451705 140178033769536 model_lib_v2.py:705] Step 4900 per-step time 0.309s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0384994,\n"," 'Loss/localization_loss': 0.013717846,\n"," 'Loss/regularization_loss': 0.123901375,\n"," 'Loss/total_loss': 0.17611861,\n"," 'learning_rate': 0.07875605}\n","I0122 12:45:01.452017 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0384994,\n"," 'Loss/localization_loss': 0.013717846,\n"," 'Loss/regularization_loss': 0.123901375,\n"," 'Loss/total_loss': 0.17611861,\n"," 'learning_rate': 0.07875605}\n","INFO:tensorflow:Step 5000 per-step time 0.308s\n","I0122 12:45:32.236895 140178033769536 model_lib_v2.py:705] Step 5000 per-step time 0.308s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0312176,\n"," 'Loss/localization_loss': 0.010694457,\n"," 'Loss/regularization_loss': 0.12327094,\n"," 'Loss/total_loss': 0.165183,\n"," 'learning_rate': 0.078691795}\n","I0122 12:45:32.237177 140178033769536 model_lib_v2.py:708] {'Loss/classification_loss': 0.0312176,\n"," 'Loss/localization_loss': 0.010694457,\n"," 'Loss/regularization_loss': 0.12327094,\n"," 'Loss/total_loss': 0.165183,\n"," 'learning_rate': 0.078691795}\n"]}],"source":["# Run training!\n","pipeline_file = '/content/models/benj/pipeline_file.config'\n","model_dir = '/content/training/'\n","\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51617,"status":"ok","timestamp":1674391587784,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"9v4ZDtTHTD5R","outputId":"d67e7b76-3fe1-4ec0-abf0-7923e5d36d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/usr/local/lib/python3.8/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","2023-01-22 12:45:40.194799: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-01-22 12:45:48.686553: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f8ec0221fd0>, because it is not built.\n","W0122 12:45:50.506600 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f8ec0221fd0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8ec01ade20>, because it is not built.\n","W0122 12:45:50.741360 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8ec01ade20>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f749970>, because it is not built.\n","W0122 12:45:50.741616 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f749970>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f749ca0>, because it is not built.\n","W0122 12:45:50.741736 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f749ca0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e4f749f10>, because it is not built.\n","W0122 12:45:50.741832 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e4f749f10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f749ee0>, because it is not built.\n","W0122 12:45:50.741925 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f749ee0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662b40a0>, because it is not built.\n","W0122 12:45:50.742012 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662b40a0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e662b4490>, because it is not built.\n","W0122 12:45:50.742095 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e662b4490>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662b4e80>, because it is not built.\n","W0122 12:45:50.742191 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662b4e80>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6636e2b0>, because it is not built.\n","W0122 12:45:50.742269 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6636e2b0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e666779a0>, because it is not built.\n","W0122 12:45:50.742347 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f8e666779a0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662fb7c0>, because it is not built.\n","W0122 12:45:50.742443 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662fb7c0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662fb850>, because it is not built.\n","W0122 12:45:50.742523 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662fb850>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae430>, because it is not built.\n","W0122 12:45:50.742627 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae430>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f75c7f0>, because it is not built.\n","W0122 12:45:50.742709 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f75c7f0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d9340>, because it is not built.\n","W0122 12:45:50.742790 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d9340>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d97f0>, because it is not built.\n","W0122 12:45:50.742871 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d97f0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d95b0>, because it is not built.\n","W0122 12:45:50.742951 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d95b0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d9af0>, because it is not built.\n","W0122 12:45:50.743038 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d9af0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d9ac0>, because it is not built.\n","W0122 12:45:50.743130 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e662d9ac0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d9df0>, because it is not built.\n","W0122 12:45:50.743220 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e662d9df0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae460>, because it is not built.\n","W0122 12:45:50.743301 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae460>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f687280>, because it is not built.\n","W0122 12:45:50.743381 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f687280>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f7734c0>, because it is not built.\n","W0122 12:45:50.743464 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f7734c0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f773790>, because it is not built.\n","W0122 12:45:50.743554 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f773790>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f773c40>, because it is not built.\n","W0122 12:45:50.743644 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f773c40>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f773cd0>, because it is not built.\n","W0122 12:45:50.743919 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f773cd0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f773b20>, because it is not built.\n","W0122 12:45:50.744080 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f773b20>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f7734f0>, because it is not built.\n","W0122 12:45:50.744186 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f7734f0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae490>, because it is not built.\n","W0122 12:45:50.744279 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec00ae490>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f689a60>, because it is not built.\n","W0122 12:45:50.744387 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f689a60>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f686a90>, because it is not built.\n","W0122 12:45:50.744473 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f686a90>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f686a00>, because it is not built.\n","W0122 12:45:50.744587 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f686a00>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f686d30>, because it is not built.\n","W0122 12:45:50.744691 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f686d30>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f686d60>, because it is not built.\n","W0122 12:45:50.744776 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f686d60>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f769940>, because it is not built.\n","W0122 12:45:50.744856 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e4f769940>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f7699a0>, because it is not built.\n","W0122 12:45:50.744935 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e4f7699a0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec001efd0>, because it is not built.\n","W0122 12:45:50.745023 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8ec001efd0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e661c6490>, because it is not built.\n","W0122 12:45:50.745103 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e661c6490>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669bcd0>, because it is not built.\n","W0122 12:45:50.745184 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669bcd0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b5b0>, because it is not built.\n","W0122 12:45:50.745261 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b5b0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669b520>, because it is not built.\n","W0122 12:45:50.745338 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669b520>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b6a0>, because it is not built.\n","W0122 12:45:50.745414 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b6a0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669b130>, because it is not built.\n","W0122 12:45:50.745489 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f8e6669b130>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b670>, because it is not built.\n","W0122 12:45:50.813428 140253219073088 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f8e6669b670>, because it is not built.\n","W0122 12:46:06.375500 140253219073088 save.py:260] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 104). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/custom_model_lite/saved_model/assets\n","I0122 12:46:11.325002 140253219073088 builder_impl.py:779] Assets written to: /content/custom_model_lite/saved_model/assets\n"]}],"source":["# Make a directory to store the trained TFLite model\n","!mkdir /content/custom_model_lite\n","output_directory = '/content/custom_model_lite'\n","\n","# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n","last_model_path = '/content/training'\n","\n","!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}\n","\n","# Convert exported graph file into TFLite model file\n","import tensorflow as tf\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n","tflite_model = converter.convert()\n","\n","with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n","  f.write(tflite_model)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1674391587784,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"URHmfiCmTmgB"},"outputs":[],"source":["# Import packages\n","import os\n","import cv2\n","import numpy as np\n","import sys\n","import glob\n","import random\n","import importlib.util\n","from tensorflow.lite.python.interpreter import Interpreter\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","### Define function for inferencing with TFLite model and displaying results\n","\n","def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n","\n","  # Grab filenames of all images in test folder\n","  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n","\n","  # Load the label map into memory\n","  with open(lblpath, 'r') as f:\n","      labels = [line.strip() for line in f.readlines()]\n","\n","  # Load the Tensorflow Lite model into memory\n","  interpreter = Interpreter(model_path=modelpath)\n","  interpreter.allocate_tensors()\n","\n","  # Get model details\n","  input_details = interpreter.get_input_details()\n","  output_details = interpreter.get_output_details()\n","  height = input_details[0]['shape'][1]\n","  width = input_details[0]['shape'][2]\n","\n","  float_input = (input_details[0]['dtype'] == np.float32)\n","\n","  input_mean = 127.5\n","  input_std = 127.5\n","\n","  # Randomly select test images\n","  images_to_test = random.sample(images, num_test_images)\n","\n","  # Loop over every image and perform detection\n","  for image_path in images_to_test:\n","\n","      # Load image and resize to expected shape [1xHxWx3]\n","      image = cv2.imread(image_path)\n","      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      imH, imW, _ = image.shape \n","      image_resized = cv2.resize(image_rgb, (width, height))\n","      input_data = np.expand_dims(image_resized, axis=0)\n","\n","      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n","      if float_input:\n","          input_data = (np.float32(input_data) - input_mean) / input_std\n","\n","      # Perform the actual detection by running the model with the image as input\n","      interpreter.set_tensor(input_details[0]['index'],input_data)\n","      interpreter.invoke()\n","\n","      # Retrieve detection results\n","      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n","      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n","      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n","\n","      detections = []\n","\n","      # Loop over all detections and draw detection box if confidence is above minimum threshold\n","      for i in range(len(scores)):\n","          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n","\n","              # Get bounding box coordinates and draw box\n","              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n","              ymin = int(max(1,(boxes[i][0] * imH)))\n","              xmin = int(max(1,(boxes[i][1] * imW)))\n","              ymax = int(min(imH,(boxes[i][2] * imH)))\n","              xmax = int(min(imW,(boxes[i][3] * imW)))\n","              \n","              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n","\n","              # Draw label\n","              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n","              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n","              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n","              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n","              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n","              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n","\n","              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n","\n","      \n","      # All the results have been drawn on the image, now display the image\n","      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n","        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n","        plt.figure(figsize=(12,16))\n","        plt.imshow(image)\n","        plt.show()\n","      \n","      # Save detection results in .txt files (for calculating mAP)\n","      elif txt_only == True:\n","\n","        # Get filenames and paths\n","        image_fn = os.path.basename(image_path)      \n","        base_fn, ext = os.path.splitext(image_fn)\n","        txt_result_fn = base_fn +'.txt'\n","        txt_savepath = os.path.join(savepath, txt_result_fn)\n","\n","        # Write results to text file\n","        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n","        with open(txt_savepath,'w') as f:\n","            for detection in detections:\n","                print(detection)\n","                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n","\n","  return"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LcISrw5QQhenWJIaavJnOWOgdlUYwCks"},"executionInfo":{"elapsed":15352,"status":"ok","timestamp":1674391627732,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"},"user_tz":-60},"id":"Aje4N_QFTse1","outputId":"ab607750-77e9-4147-8d7f-cab1150cd09b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Set up variables for running user's model\n","PATH_TO_IMAGES='/content/images/test'   # Path to test images folder\n","PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # Path to .tflite model file\n","PATH_TO_LABELS='/content/labelmap.txt'   # Path to labelmap.txt file\n","min_conf_threshold=0.80   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n","images_to_test = 10   # Number of images to run detection on\n","\n","# Run inferencing function!\n","tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"]},{"cell_type":"code","source":["from google.colab import files\n","files.download('/content/custom_model_lite/detect.tflite')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"7X29NCerjQCs","executionInfo":{"status":"ok","timestamp":1674392785330,"user_tz":-60,"elapsed":383,"user":{"displayName":"benjamin vierstaete","userId":"16764205195922165198"}},"outputId":"6ee8f5e0-1101-44bb-f6d7-c5c7169f52c0"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e525cfd5-4be2-4cfa-8556-bc24a4d93e73\", \"detect.tflite\", 11497428)"]},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOrwgTMzwn0NZn9Sw6LaL2r"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}